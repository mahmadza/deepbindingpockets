{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1325c82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "728fa79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-ae932be897c3>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "137090a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_name = '/CPU:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13ee53be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "578320e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator function\n",
    "def make_generator_network(num_hidden_layers = 1,\n",
    "                          num_hidden_units = 100,\n",
    "                          num_output_units = 784):\n",
    "    model = tf.keras.Sequential()\n",
    "    for i in range(num_hidden_layers):\n",
    "        model.add(tf.keras.layers.Dense(units=num_hidden_units,\n",
    "                                       use_bias = False))\n",
    "        model.add(tf.keras.layers.LeakyReLU())\n",
    "        \n",
    "    model.add(tf.keras.layers.Dense(units = num_output_units,\n",
    "                                   activation = 'tanh'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54aa3e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminator function\n",
    "def make_discriminator_network(num_hidden_layers = 1,\n",
    "                              num_hidden_units = 100,\n",
    "                              num_output_units = 1):\n",
    "    model = tf.keras.Sequential()\n",
    "    for i in range(num_hidden_layers):\n",
    "        model.add(tf.keras.layers.Dense(units = num_hidden_units))\n",
    "        model.add(tf.keras.layers.LeakyReLU())\n",
    "        model.add(tf.keras.layers.Dropout(rate = 0.5))\n",
    "    model.add(tf.keras.layers.Dense(units = num_output_units,\n",
    "                                   activation = None))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6992cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (28, 28)\n",
    "z_size = 20\n",
    "mode_z = 'uniform'\n",
    "gen_hidden_layers = 1\n",
    "gen_hidden_size = 20    #100 in the book\n",
    "disc_hidden_layers = 1\n",
    "disc_hidden_size = 20   #100 in the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acba7919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                400       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 784)               16464     \n",
      "=================================================================\n",
      "Total params: 16,864\n",
      "Trainable params: 16,864\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "gen_model = make_generator_network(num_hidden_layers = gen_hidden_layers,\n",
    "                                  num_hidden_units = gen_hidden_size,\n",
    "                                  num_output_units = np.prod(image_size))\n",
    "gen_model.build(input_shape = (None, z_size))\n",
    "gen_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ee43e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 20)                15700     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 15,721\n",
      "Trainable params: 15,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "disc_model = make_discriminator_network(num_hidden_layers=disc_hidden_layers,\n",
    "                                       num_hidden_units = disc_hidden_size)\n",
    "disc_model.build(input_shape = (None, np.prod(image_size)))\n",
    "disc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a7773e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found a different version 3.0.1 of dataset mnist in data_dir /Users/zabidi/tensorflow_datasets. Using currently defined version 2.0.0.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2d5a5e62c843>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# defining training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmnist_bldr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mnist'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'2.0.0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmnist_bldr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_and_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmnist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist_bldr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffle_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/ML_2020/lib/python3.6/site-packages/tensorflow_datasets/core/api_utils.py\u001b[0m in \u001b[0;36mdisallow_positional_args_dec\u001b[0;34m(fn, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0m_check_no_positional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mismethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallowed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0m_check_required\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdisallow_positional_args_dec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/ML_2020/lib/python3.6/site-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36mdownload_and_prepare\u001b[0;34m(self, download_dir, download_config)\u001b[0m\n\u001b[1;32m    260\u001b[0m     dl_manager = self._make_download_manager(\n\u001b[1;32m    261\u001b[0m         \u001b[0mdownload_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         download_config=download_config)\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# Currently it's not possible to overwrite the data because it would\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/ML_2020/lib/python3.6/site-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36m_make_download_manager\u001b[0;34m(self, download_dir, download_config)\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0mforce_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFORCE_REDOWNLOAD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0mforce_extraction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFORCE_REDOWNLOAD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m         \u001b[0mregister_checksums\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_checksums\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m     )\n\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/ML_2020/lib/python3.6/site-packages/tensorflow_datasets/core/api_utils.py\u001b[0m in \u001b[0;36mdisallow_positional_args_dec\u001b[0;34m(fn, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0m_check_no_positional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mismethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallowed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0m_check_required\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdisallow_positional_args_dec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/ML_2020/lib/python3.6/site-packages/tensorflow_datasets/core/download/download_manager.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, download_dir, extract_dir, manual_dir, dataset_name, force_download, force_extraction, register_checksums)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_checksums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregister_checksums\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;31m# All known URLs: {url: (size, checksum)}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sizes_checksums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchecksums\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_sizes_checksums\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0;31m# To record what is being used: {url: (size, checksum)}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recorded_sizes_checksums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/ML_2020/lib/python3.6/site-packages/tensorflow_datasets/core/download/checksums.py\u001b[0m in \u001b[0;36mget_all_sizes_checksums\u001b[0;34m()\u001b[0m\n\u001b[1;32m    127\u001b[0m   \u001b[0msizes_checksums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_checksum_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_sizes_checksums\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_checksum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m       if (url in sizes_checksums and\n",
      "\u001b[0;32m//anaconda3/envs/ML_2020/lib/python3.6/site-packages/tensorflow_datasets/core/download/checksums.py\u001b[0m in \u001b[0;36m_get_sizes_checksums\u001b[0;34m(checksums_path)\u001b[0m\n\u001b[1;32m    117\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;31m# URL might have spaces inside, but size and checksum will not.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchecksum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0mchecksums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchecksum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mchecksums\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 1)"
     ]
    }
   ],
   "source": [
    "# defining training set\n",
    "mnist_bldr = tfds.builder('mnist', version = '2.0.0')\n",
    "mnist_bldr.download_and_prepare()\n",
    "mnist = mnist_bldr.as_dataset(shuffle_files = False)\n",
    "\n",
    "def preprocess(ex, mode = 'uniform'):\n",
    "    image = ex['image']\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.reshape(image, [-1])\n",
    "    image = image * 2 - 1.0\n",
    "    if mode == 'uniform':\n",
    "        input_z = tf.random.uniform(shape = (z_size, ),\n",
    "                                   minval = -1.0,\n",
    "                                   maxval = 1.0)\n",
    "    elif mode == 'normal':\n",
    "        input_z = tf.random.normal(shape = (z_size,))\n",
    "    return input_z, image\n",
    "\n",
    "mnist_trainset = mnist['train']\n",
    "mnist_trainset = mnist_trainset.map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80df220b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"//anaconda3/envs/ML_2020/bin/pip\", line 7, in <module>\r\n",
      "    from pip._internal.cli.main import main\r\n",
      "  File \"//anaconda3/envs/ML_2020/lib/python3.6/site-packages/pip/_internal/cli/main.py\", line 8, in <module>\r\n",
      "    from pip._internal.cli.autocompletion import autocomplete\r\n",
      "  File \"//anaconda3/envs/ML_2020/lib/python3.6/site-packages/pip/_internal/cli/autocompletion.py\", line 9, in <module>\r\n",
      "    from pip._internal.cli.main_parser import create_main_parser\r\n",
      "  File \"//anaconda3/envs/ML_2020/lib/python3.6/site-packages/pip/_internal/cli/main_parser.py\", line 7, in <module>\r\n",
      "    from pip._internal.cli import cmdoptions\r\n",
      "  File \"//anaconda3/envs/ML_2020/lib/python3.6/site-packages/pip/_internal/cli/cmdoptions.py\", line 22, in <module>\r\n",
      "    from pip._internal.cli.progress_bars import BAR_TYPES\r\n",
      "  File \"//anaconda3/envs/ML_2020/lib/python3.6/site-packages/pip/_internal/cli/progress_bars.py\", line 9, in <module>\r\n",
      "    from pip._internal.utils.logging import get_indentation\r\n",
      "  File \"//anaconda3/envs/ML_2020/lib/python3.6/site-packages/pip/_internal/utils/logging.py\", line 14, in <module>\r\n",
      "    from pip._internal.utils.misc import ensure_dir\r\n",
      "  File \"//anaconda3/envs/ML_2020/lib/python3.6/site-packages/pip/_internal/utils/misc.py\", line 29, in <module>\r\n",
      "    from pip._internal.locations import get_major_minor_version, site_packages, user_site\r\n",
      "  File \"//anaconda3/envs/ML_2020/lib/python3.6/site-packages/pip/_internal/locations/__init__.py\", line 9, in <module>\r\n",
      "    from . import _distutils, _sysconfig\r\n",
      "  File \"//anaconda3/envs/ML_2020/lib/python3.6/site-packages/pip/_internal/locations/_sysconfig.py\", line 8, in <module>\r\n",
      "    from pip._internal.exceptions import InvalidSchemeCombination, UserInstallationInvalid\r\n",
      "ImportError: cannot import name 'InvalidSchemeCombination'\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-datasets --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6390be49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246edff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cd16d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780f3dac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ce2b09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a602f34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985556e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd1192d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e60c99b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c356cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
