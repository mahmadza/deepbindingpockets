{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9df979e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length:  1112350\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open('../../1268-0.txt', 'r') as fp:\n",
    "    text = fp.read()\n",
    "    \n",
    "start_index = text.find('THE MYSTERIOUS ISLAND')\n",
    "end_index = text.find('End of the Project Gutenberg')\n",
    "text = text[start_index:end_index]\n",
    "char_set = set(text)\n",
    "print('Total length: ', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dde7b5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Characters:  80\n"
     ]
    }
   ],
   "source": [
    "print('Unique Characters: ', len(char_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6423ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text encoded shape:  (1112350,)\n"
     ]
    }
   ],
   "source": [
    "chars_sorted = sorted(char_set)\n",
    "char2int = {ch:i for i,ch in enumerate(chars_sorted)}\n",
    "char_array = np.array(chars_sorted)\n",
    "\n",
    "text_encoded = np.array([char2int[ch] for ch in text],\n",
    "                       dtype = np.int32)\n",
    "print('Text encoded shape: ', text_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6030798b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE MYSTERIOUS  --encoding--->  [44 32 29  1 37 48 43 44 29 42 33 39 45 43  1]\n"
     ]
    }
   ],
   "source": [
    "print(text[:15], '--encoding---> ', text_encoded[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4f54ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33 43 36 25 38 28] ---reverse--->  ISLAND\n"
     ]
    }
   ],
   "source": [
    "print(text_encoded[15:21], '---reverse---> ', ''.join(char_array[text_encoded[15:21]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6acd3e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 -> T\n",
      "32 -> H\n",
      "29 -> E\n",
      "1 ->  \n",
      "37 -> M\n"
     ]
    }
   ],
   "source": [
    "# create a tensorflow dataset\n",
    "import tensorflow as tf\n",
    "ds_text_encoded = tf.data.Dataset.from_tensor_slices(text_encoded)\n",
    "# verify\n",
    "for ex in ds_text_encoded.take(5):\n",
    "    print('{} -> {}'.format(ex.numpy(), char_array[ex.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a748503a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 40\n",
    "chunk_size = seq_length + 1\n",
    "ds_chunks = ds_text_encoded.batch(chunk_size, drop_remainder=True)\n",
    "\n",
    "# function to split x and y\n",
    "def split_input_target(chunk):\n",
    "    input_seq = chunk[:-1]\n",
    "    target_seq = chunk[1:]\n",
    "    return input_seq, target_seq\n",
    "\n",
    "ds_sequences = ds_chunks.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eacdfe9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input, x:  'THE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced b'\n",
      "Target, y:  'HE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced by'\n",
      "Input, x:  ' Anthony Matonak, and Trevor Carlson\\n\\n\\n\\n'\n",
      "Target, y:  'Anthony Matonak, and Trevor Carlson\\n\\n\\n\\n\\n'\n"
     ]
    }
   ],
   "source": [
    "# verify\n",
    "for example in ds_sequences.take(2):\n",
    "    print('Input, x: ',repr(''.join(char_array[example[0].numpy()])))\n",
    "    print('Target, y: ',repr(''.join(char_array[example[1].numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26d72cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the dataset into mini-batches\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "ds = ds_sequences.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5c2dd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an RNN model using Keras Sequential class\n",
    "def build_model(vocab_size, embedding_dim, rnn_units):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences = True),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efec0438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "charset_size = len(char_array)\n",
    "embedding_dim = 256\n",
    "rnn_units = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a8729ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 256)         20480     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, None, 512)         1574912   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, None, 80)          41040     \n",
      "=================================================================\n",
      "Total params: 1,636,432\n",
      "Trainable params: 1,636,432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "tf.random.set_seed(1)\n",
    "model = build_model(vocab_size = charset_size,\n",
    "                   embedding_dim = embedding_dim,\n",
    "                   rnn_units = rnn_units)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c95b382f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "424/424 [==============================] - 320s 749ms/step - loss: 2.7378\n",
      "Epoch 2/20\n",
      "424/424 [==============================] - 330s 775ms/step - loss: 1.8178\n",
      "Epoch 3/20\n",
      "424/424 [==============================] - 271s 636ms/step - loss: 1.5882\n",
      "Epoch 4/20\n",
      "424/424 [==============================] - 265s 622ms/step - loss: 1.4553\n",
      "Epoch 5/20\n",
      "424/424 [==============================] - 247s 580ms/step - loss: 1.3805\n",
      "Epoch 6/20\n",
      "424/424 [==============================] - 255s 598ms/step - loss: 1.3213\n",
      "Epoch 7/20\n",
      "424/424 [==============================] - 247s 580ms/step - loss: 1.2786\n",
      "Epoch 8/20\n",
      "424/424 [==============================] - 284s 669ms/step - loss: 1.2436\n",
      "Epoch 9/20\n",
      "424/424 [==============================] - 342s 792ms/step - loss: 1.2206\n",
      "Epoch 10/20\n",
      "424/424 [==============================] - 254s 595ms/step - loss: 1.1930\n",
      "Epoch 11/20\n",
      "424/424 [==============================] - 219s 516ms/step - loss: 1.1745\n",
      "Epoch 12/20\n",
      "424/424 [==============================] - 216s 507ms/step - loss: 1.1499\n",
      "Epoch 13/20\n",
      "424/424 [==============================] - 220s 518ms/step - loss: 1.1367\n",
      "Epoch 14/20\n",
      "424/424 [==============================] - 234s 549ms/step - loss: 1.1197\n",
      "Epoch 15/20\n",
      "424/424 [==============================] - 259s 609ms/step - loss: 1.1058\n",
      "Epoch 16/20\n",
      "424/424 [==============================] - 239s 561ms/step - loss: 1.0910\n",
      "Epoch 17/20\n",
      "424/424 [==============================] - 225s 528ms/step - loss: 1.0766\n",
      "Epoch 18/20\n",
      "424/424 [==============================] - 225s 529ms/step - loss: 1.0645\n",
      "Epoch 19/20\n",
      "424/424 [==============================] - 221s 519ms/step - loss: 1.0492\n",
      "Epoch 20/20\n",
      "424/424 [==============================] - 223s 523ms/step - loss: 1.0382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x145eac1d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
    "model.fit(ds, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "006dc5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities:  [0.33333334 0.33333334 0.33333334]\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "logits = [[1.0, 1.0, 1.0]]\n",
    "print('Probabilities: ', tf.math.softmax(logits).numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b1f7eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[0, 0, 1, 2, 0, 0, 0, 0, 1, 0]])\n"
     ]
    }
   ],
   "source": [
    "samples = tf.random.categorical(logits=logits, num_samples=10)\n",
    "tf.print(samples.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70e69cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model, starting_str, len_generated_text = 500,\n",
    "          max_input_length = 40, scale_factor = 1.0):\n",
    "    \n",
    "    encoded_input = [char2int[s] for s in starting_str]\n",
    "    encoded_input = tf.reshape(encoded_input, (1, -1))\n",
    "    \n",
    "    generated_str = starting_str\n",
    "    model.reset_states()\n",
    "    \n",
    "    for i in range(len_generated_text):\n",
    "        logits = model(encoded_input)\n",
    "        logits = tf.squeeze(logits, 0)\n",
    "        scaled_logits = logits * scale_factor\n",
    "        new_char_indx = tf.random.categorical(scaled_logits,\n",
    "                                             num_samples = 1)\n",
    "        new_char_indx = tf.squeeze(new_char_indx)[-1].numpy()\n",
    "        generated_str += str(char_array[new_char_indx])\n",
    "        new_char_indx = tf.expand_dims([new_char_indx], 0)\n",
    "        encoded_input = tf.concat([encoded_input, new_char_indx],\n",
    "                                 axis = 1)\n",
    "        encoded_input = encoded_input[:, -max_input_length:]\n",
    "        \n",
    "    return generated_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910c9946",
   "metadata": {},
   "source": [
    "### Try different scaling factor, to test for behavior difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fb9a327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Island was obliged to separate\n",
      "the latter about the palisade. The rooms turn to safe raising\n",
      "himself in the darkerque reporter, “and I fearing able to remark.”\n",
      "\n",
      "During the boat?” cried Neb. He suited the boat was proud Pencroft, for everything!”\n",
      "\n",
      "“What can is not a moment than laster rushed like those six height a hour efflace of extreme shot, why sparkled themose vessel, hisimate of rocks. A narrow point of the settlers were soon torn a few minutes, on the\n",
      "evergrety of the piles, each other, and the \n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "print(sample(model, starting_str = 'The Island'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bd01ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities before scaling:  [0.10650698 0.10650698 0.78698604]\n"
     ]
    }
   ],
   "source": [
    "logits = np.array([[1.0, 1.0, 3.0]])\n",
    "print(\"Probabilities before scaling: \",\n",
    "      tf.math.softmax(logits).numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59370916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities after 0.5 scaling:  [0.21194156 0.21194156 0.57611688]\n"
     ]
    }
   ],
   "source": [
    "print(\"Probabilities after 0.5 scaling: \",\n",
    "      tf.math.softmax(0.5 * logits).numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce850b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities after 0.1 scaling:  [0.31042377 0.31042377 0.37915245]\n"
     ]
    }
   ],
   "source": [
    "print(\"Probabilities after 0.1 scaling: \",\n",
    "      tf.math.softmax(0.1 * logits).numpy()[0])\n",
    "# will give near-uniform probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e64db948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island was so feared that the bridge was not a few days afterwards the interior of the corral, and the colonists were not more than five minutes after the waves had disappeared, and the ball had been seen that she would\n",
      "have had no doubt that they were all the position the colonists, now accomplished his eyes.\n",
      "\n",
      "The colonists left the sailor and his companions were therefore put off the corral was not to be feared the door, and the time the cart was not a malignant precaution of the cavern, and the sea\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "# scale factor = 2, stable\n",
    "print(sample(model, starting_str = 'The island',\n",
    "            scale_factor = 2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b851612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island\n",
      "veilbated zulreate vi, rowervan, doveled imenyced from\n",
      "them an\n",
      "eart,” replied Gideox SUNevary!\n",
      "\n",
      "Bo’,-of\n",
      "whom crunkp, though this toh, forewards.-!”0 whole ut, yir withs, an hourbrafat’s return on the vessel an hast?”\n",
      "\n",
      "Pisig a tinder’ must, caje no carro, ofing.\n",
      "jumaged only Harding wanting smallow strett!”\n",
      "\n",
      "Top! Gideon finater-Jainetuatebrin reageedly tates.\n",
      "Hings.\n",
      "\n",
      "“Ow5-thers? I\n",
      "fourt\n",
      "Jithougn aravi!’s!\n",
      "colmiNargue ordshight on Toiplos--ir by, with-Alread,? Sidving had rulAlto-zincamescent bir\n"
     ]
    }
   ],
   "source": [
    "# scale factor = 0.5, more randomness\n",
    "print(sample(model, starting_str = 'The island',\n",
    "            scale_factor = 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1c7148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c222cd04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afadb0bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c3d05e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0297d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0948f36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c6a0c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e920e62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
